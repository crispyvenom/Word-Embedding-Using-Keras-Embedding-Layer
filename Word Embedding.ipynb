{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1a71da-0e85-408f-b275-3b1b9903207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:34:40.096854: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-12 22:34:40.097073: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-12 22:34:40.113292: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-12 22:34:40.179140: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-12 22:34:41.554018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1699ba38-7863-4483-8789-f388aa274f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad92afe7-a11f-4979-8e1c-948509ac582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:34:43.385808: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-12 22:34:43.491791: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-12 22:34:43.491866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a620747-35ec-480f-9535-d24a7a350394",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['nice food',\n",
    "           'amazing restaurant',\n",
    "           'too good',\n",
    "           'just loved it!',\n",
    "           'will go again',\n",
    "           'horrible food',\n",
    "           'never go there',\n",
    "           'poor service',\n",
    "           'poor quality',\n",
    "           'needs improvement']\n",
    "\n",
    "sentiment = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97bc43d0-285d-404f-bd7f-794c6104f6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(\"amazing restaurant\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7235fecc-d00b-41a2-9c99-96d225ab536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28, 47], [4, 9], [24, 7], [5, 48, 14], [25, 29, 32], [1, 47], [31, 29, 18], [24, 27], [24, 33], [49, 2]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50\n",
    "encoded_reviews = [one_hot(d, vocab_size) for d in reviews]\n",
    "print(encoded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "771fee81-28bc-4d62-80d3-52fa97f845d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28, 47],\n",
       " [4, 9],\n",
       " [24, 7],\n",
       " [5, 48, 14],\n",
       " [25, 29, 32],\n",
       " [1, 47],\n",
       " [31, 29, 18],\n",
       " [24, 27],\n",
       " [24, 33],\n",
       " [49, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4dbb2a0-1cda-498f-b7f2-f46faa27f041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 47,  0],\n",
       "       [ 4,  9,  0],\n",
       "       [24,  7,  0],\n",
       "       [ 5, 48, 14],\n",
       "       [25, 29, 32],\n",
       "       [ 1, 47,  0],\n",
       "       [31, 29, 18],\n",
       "       [24, 27,  0],\n",
       "       [24, 33,  0],\n",
       "       [49,  2,  0]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 3\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "padded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67253562-9aec-4bb5-bb98-bcd09828e9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:34:43.662587: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-12 22:34:43.662735: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-12 22:34:43.662789: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-12 22:34:44.186542: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-12 22:34:44.186720: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-12 22:34:44.186740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-12 22:34:44.186797: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-12 22:34:44.186890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2255 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "embedded_vector_size = 5\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedded_vector_size, input_length=max_length, name=\"embedding\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54eabd1b-e045-4ff6-88db-0c62c39d1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = padded_reviews\n",
    "y = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f806107d-d64d-40e9-a611-dba1e3a7b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 5)              250       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266 (1.04 KB)\n",
      "Trainable params: 266 (1.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da0c5ded-f173-40d6-bca0-00d6f1a758bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:34:46.520092: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fde3033ea90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-12 22:34:46.520173: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti, Compute Capability 7.5\n",
      "2024-02-12 22:34:46.535229: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-12 22:34:46.576634: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707757486.732174    2135 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fdf23d17e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc0195f-cabe-4a6f-a556-fcf89ec1ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6200 - accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b9ce009-b2de-4ea3-9de3-bb8a90bf187a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea10e5b9-ad1d-4204-b033-5dcbfeba150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07261591,  0.05772696, -0.07496065,  0.03076631, -0.07026308],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44927776-90ed-4866-8ead-0f84319aceda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01285178,  0.0642539 , -0.05531663,  0.00388419, -0.01652565],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482bf8b5-b3c7-4156-a6d2-d4fba69357e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
